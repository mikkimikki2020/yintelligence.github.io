<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Artificial Neural Networks, Chaoqun Yin">
    <meta name="description" content="Veni, Vidi, Vici">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Artificial Neural Networks | Chaoqun Yin</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.3.0"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Chaoqun Yin</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Chaoqun Yin</div>
        <div class="logo-desc">
            
            Veni, Vidi, Vici
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/16.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Artificial Neural Networks</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Techniques-of-Artificial-Intelligence/">
                                <span class="chip bg-color">Techniques of Artificial Intelligence</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Notes/" class="post-category">
                                Notes
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2021-03-07
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>Update Date:&nbsp;&nbsp;
                    2021-03-30
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    2.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    15 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="artificial-neural-networks">Artificial Neural Networks</h1>
<h2 id="outline">Outline</h2>
<ul>
<li>Motivation for neural processing</li>
<li>Neural basis</li>
<li>Perceptrons</li>
<li>Training</li>
<li>Testing</li>
</ul>
<h2 id="motivation">Motivation</h2>
<ul>
<li>Computers are not like brains/bodies
<ul>
<li>they are better than brains at some things
<ul>
<li>symbolic calculations</li>
<li>reliably doing what they are told</li>
</ul></li>
<li>they are (much) worse than brains/bodies at others
<ul>
<li>understanding human language</li>
<li>learning</li>
<li>perceiving (ie seeing, hearing)</li>
</ul></li>
</ul></li>
<li>Question
<ul>
<li>Can we build computers and/or programs that are (more) like brains?</li>
<li>If so, is it useful?</li>
</ul></li>
</ul>
<h2 id="von-neumann-architecture">von Neumann architecture</h2>
<p><img src="/images/AI/185218.png" /></p>
<h2 id="neural-architecture">Neural architecture</h2>
<ul>
<li>The brain doesn’t seem to have a CPU
<ul>
<li>Instead, it has many simple, parallel, asynchronous units, called neurons</li>
</ul></li>
<li>Each neuron is a single cell, with
<ul>
<li>some relatively short fibres, called dendrites</li>
<li>one long fibre, called an axon</li>
</ul></li>
<li>The end of the axon branches out into more short fibres</li>
<li>Each fibre “connects” to the dendrites and cell bodies of other neurons
<ul>
<li>The “connection” is actually a tiny gap, called a synapse</li>
</ul></li>
<li>Axons are transmitters, dendrites are receivers</li>
</ul>
<h3 id="neural-architecture-neuron">Neural architecture: neuron</h3>
<p><img src="/images/AI/1852180.png" /></p>
<ul>
<li>The fibres of surrounding neurons emit chemicals (neurotransmitters) that move across the synapse and change the electrical potential applied to the cell body
<ul>
<li>Sometimes the transmission across the synapse increases the potential, and sometimes decreases it</li>
</ul></li>
<li>When the potential reaches a certain threshold, an electrical pulse, or action potential, travels down the axon, eventually reaching all the branches, causing them to release their neurotransmitters
<ul>
<li>And so on through the network</li>
</ul></li>
</ul>
<h3 id="neural-architecture-neuroplasticity">Neural architecture: neuroplasticity</h3>
<ul>
<li>Neuroplasticity or brain plasticity is the brain’s ability to change during life</li>
<li>The brain can reorganise itself
<ul>
<li>by forming new connections between brain cells (neurons)</li>
</ul></li>
<li>Neuroplasticity occurs in the brain
<ul>
<li>At the beginning of life: when the immature brain organizes itself</li>
<li>After brain injury: to compensate for lost functions or maximize remaining ones</li>
<li>Throughout life: whenever something new is learned and memorised</li>
</ul></li>
<li>For a long time, it was believed that as we age, the connections in the brain become fixed
<ul>
<li>Research has now shown that, during life, the brain never stops changing through learning</li>
</ul></li>
<li>When you become an expert in a specific kind of knowledge, the areas in your brain that deal with this type of skill will grow
<ul>
<li>For instance, London taxi drivers have a larger posterior hippocampus than London bus drivers</li>
<li>It is because this region of the hippocampus is specialised in acquiring and using complex spatial information in order to navigate efficiently</li>
<li>Taxi drivers have to navigate around London, using The Knowledge, whereas bus drivers follow a limited set of routes</li>
</ul></li>
<li>There are changes to neurons that seem to reflect or enable learning
<ul>
<li>The synaptic connections exhibit plasticity
<ul>
<li>The degree to which a neuron will react to a stimulus across a particular synapse is subject to change over time (long-term potentiation)</li>
</ul></li>
<li>Neurons create new connections to other neurons</li>
<li>Other changes in structure also seem to occur, some less well understood than others</li>
</ul></li>
</ul>
<h2 id="the-neuron-as-a-device">The Neuron as a device</h2>
<ul>
<li>There are around neurons 10<sup>12</sup> in the human brain
<ul>
<li>with, perhaps, 10<sup>14</sup> or so synapses</li>
</ul></li>
<li>Neurons are slow devices
<ul>
<li>Tens of milliseconds to do something</li>
<li>Jerome Feldman translates this into the “100 step program constraint’’
<ul>
<li>Most of the AI tasks we want to do take people less than a second</li>
<li>So any brain “program” can’t be longer than 100 neural “instructions”</li>
</ul></li>
</ul></li>
<li>No particular unit seems to be more important than any other
<ul>
<li>Destroying any one brain cell has little effect on overall processing</li>
</ul></li>
</ul>
<h2 id="how-do-neurons-do-it">How do neurons do it?</h2>
<ul>
<li>All the billions of neurons in the brain are active at once ‣ So this is truly massive parallelism</li>
<li>But it’s probably not the kind of parallelism that we are used to in conventional Computer Science
<ul>
<li>Sending messages (i.e., complex patterns that encode information) is probably too slow to work</li>
<li>So information is probably encoded some other way
<ul>
<li>e.g., by the connections themselves</li>
</ul></li>
</ul></li>
<li>Maybe we can explain cognition by densely connected networks transmitting simple signals
<ul>
<li>Connectionist computing (Feldman)</li>
<li>Parallel Distributed Processing (PDP; Rumelhart, McClelland, Hinton)</li>
<li>(Artificial) Neural Networks</li>
</ul></li>
</ul>
<h2 id="perceptrons">Perceptrons</h2>
<ul>
<li>Many connectionists use the same simple model of a neural system</li>
<li>There is a collection of units, each of which has
<ul>
<li>some weighted inputs from other units
<ul>
<li>inputs represent the degree to which other units are active (firing)</li>
<li>weights represent how much the unit is affected by the activity of the other units</li>
</ul></li>
<li>a threshold that the sum of the weighted inputs must exceed to cause firing</li>
<li>a single output that connects to (an)other unit(s)
<ul>
<li>if the unit fires, the resulting action potential goes this way</li>
</ul></li>
</ul></li>
</ul>
<figure>
<img src="/images/AI/1852181.png" alt="" /><figcaption>A perceptron unit</figcaption>
</figure>
<ul>
<li>x<sub>i</sub> are inputs, reals between 0 and 1 (standard net) or -1 and 1 (bipolar net)</li>
<li>w<sub>i</sub> are weights, reals</li>
<li>w<sub>n</sub> is usually set at the threshold with x<sub>n</sub> = 1(bias)</li>
<li>y is the weighted sum of inputs including the threshold (activation level)</li>
<li>o is the output</li>
</ul>
<p>The output is computed using a function that determines how far the perceptron’s activation level is below or above 0</p>
<ul>
<li>Note that this is a loose approximation to what happens in biology
<ul>
<li>Perceptrons transmit information via real-valued numbers as inputs arrive
<ul>
<li>real neurons fire all the time, changing their firing rate, from a few pulses per second to a few hundred pulses per second</li>
<li>spiking neural networks simulate this directly—beyond scope of current module</li>
</ul></li>
</ul></li>
<li>The weights in perceptrons are not fixed, and can change
<ul>
<li>learning in a neural network is achieved by adjusting weights</li>
</ul></li>
</ul>
<h2 id="the-big-questions-for-neural-nets">The Big Questions for Neural Nets</h2>
<ul>
<li>How do we wire up a network of perceptrons?
<ul>
<li>i.e., what “architecture” do we use?</li>
</ul></li>
<li>How does the network represent knowledge?
<ul>
<li>i.e., what do the nodes and combinations of nodes mean?</li>
</ul></li>
<li>How do we set the weights?
<ul>
<li>i.e., how does learning take place?</li>
</ul></li>
</ul>
<h2 id="simplest-architecture-a-perceptron">Simplest architecture: a perceptron</h2>
<p><img src="/images/AI/1852182.png" /></p>
<ul>
<li>A basic perceptron computes o = f( X . W )
<ul>
<li>X . W = ∑<sub>i</sub> w<sub>i</sub> x<sub>i</sub> = w<sub>1</sub> . x<sub>1</sub> + w<sub>2</sub>. x<sub>2</sub> + ... + w<sub>n</sub> . 1</li>
<li>g( x ) = 1 if x ≥ 0.5 and 0 otherwise
<ul>
<li>g is the activation or transfer function</li>
<li>more complex, continuous functions (esp. sigmoid) can be used, but they all have the same basic purpose: to push the output values towards the extremes</li>
<li>without this non-linearity, the network can only learn simple linear functions</li>
<li>sigmoid function is differentiable, whereas sharp threshold is not</li>
</ul></li>
</ul></li>
</ul>
<h2 id="logical-function-and">Logical function AND</h2>
<p><img src="/images/AI/1852183.png" /></p>
<ul>
<li>Perceptrons can simulate basic logic gates, such as AND</li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">a</th>
<th style="text-align: center;">b</th>
<th style="text-align: center;">a+b-1</th>
<th style="text-align: center;">output</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">-1</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<h2 id="logical-function-or">Logical function OR</h2>
<p><img src="/images/AI/1852184.png" /></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">a</th>
<th style="text-align: center;">b</th>
<th style="text-align: center;">a+b+0</th>
<th style="text-align: center;">output</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<h2 id="training-perceptrons">Training perceptrons</h2>
<ul>
<li>Pereceptrons can be trained to compute a specific function</li>
<li>Basic training procedure
<ul>
<li>Start with a perceptron with any values for the weights (usually random)</li>
<li>Apply the input, let the perceptron compute the answer</li>
<li>If the answer is right
<ul>
<li>do nothing</li>
</ul></li>
<li>If the answer is wrong
<ul>
<li>modify the weights by adding or subtracting the input vector (perhaps scaled smaller)</li>
</ul></li>
<li>Iterate over all the input vectors, repeating as necessary, until the perceptron learns what we want, to within a predefined degree of error</li>
</ul></li>
<li>The intuition behind the basic training algorithm this is
<ul>
<li>If the unit should have gone on, but didn’t, increase the influence of the inputs that are on
<ul>
<li>adding the input (or a fraction thereof) to the weights will move in the right direction</li>
</ul></li>
<li>If the unit should have been off, but was on, decrease the influence of the units that were on
<ul>
<li>subtracting the input (of a fraction thereof) from the weights moves in the right direction</li>
</ul></li>
</ul></li>
</ul>
<h2 id="training-the-logical-or-function">Training the logical OR function</h2>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">a</th>
<th style="text-align: center;">b</th>
<th style="text-align: center;">bias</th>
<th style="text-align: center;">output</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<ul>
<li>Initially the weights are all 0
<ul>
<li>the weight vector, W = (0 0 0)</li>
</ul></li>
<li>Now we cycle through the inputs and change the weights as necessary</li>
</ul>
<p><img src="/images/AI/1852185.png" /></p>
<h2 id="training-the-logical-and-function">Training the logical AND function</h2>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">a</th>
<th style="text-align: center;">b</th>
<th style="text-align: center;">bias</th>
<th style="text-align: center;">output</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<ul>
<li>Initially the weights are all 0
<ul>
<li>the weight vector, W = (0 0 0)</li>
</ul></li>
<li>Now we cycle through the inputs and change the weights as necessary</li>
<li>Make your own table:
<ul>
<li><strong>Input Weights Result Action</strong></li>
</ul></li>
</ul>
<p><img src="/images/AI/1852186.png" /></p>
<p>And now, with α = 0.2</p>
<p><img src="/images/AI/1852187.png" /></p>
<h2 id="generalised-training-procedure">Generalised training procedure</h2>
<ul>
<li>Start with a perceptron with any values for the weights (0 or random)
<ul>
<li>Feed the input, let the perceptron compute the answer</li>
<li>If the answer is right
<ul>
<li>do nothing</li>
</ul></li>
<li>If the answer is wrong
<ul>
<li>add this factor to each weight: Δ wi = α ( y – h ) inputi</li>
</ul></li>
</ul></li>
<li>Iterate over all the input vectors, repeating as necessary, until (i.e., the weight vector converges, or |ΔW| ≤ a given constant)
<ul>
<li>each cycle through the input data is called an epoch</li>
</ul></li>
<li>Values:
<ul>
<li>α is the learning rate, 0 &lt; α ≤ 1; it prevents the values from jumping around wildly</li>
<li>y is the desired output</li>
<li>h is the actual output</li>
</ul></li>
</ul>
<h2 id="single-layer-perceptron-networks">Single-layer perceptron networks</h2>
<ul>
<li>In a single layer perceptron network there are
<ul>
<li>input units</li>
<li>output units</li>
</ul></li>
<li>There are as many perceptrons as output units
<ul>
<li>each input unit is connected to every output unit ‣ each connection has a weight</li>
<li>each output has a soft thresholding function, e.g. sigmoid (more later)</li>
</ul></li>
<li>It is possible to learn multiple functions with one training sequence
<ul>
<li>outputs are now vectors (as inputs always were)</li>
</ul></li>
</ul>
<h2 id="classifying-using-a-perceptron">Classifying using a perceptron</h2>
<ul>
<li>A (bipolar) perceptron can learn to classify data, into 2 categories
<ul>
<li>Convergence after ~500 iterations
<ul>
<li>W = (-1.13 -1.1 10.9)</li>
<li>-1.3 * x<sub>1</sub> + -1.1*x<sub>2</sub> + 10.9 = 0</li>
</ul></li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">x<sub>1</sub></th>
<th style="text-align: center;">x<sub>2</sub></th>
<th style="text-align: center;">output</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">9.4</td>
<td style="text-align: center;">6.4</td>
<td style="text-align: center;">-1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">2.1</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">8.0</td>
<td style="text-align: center;">7.7</td>
<td style="text-align: center;">-1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">2.2</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">7.9</td>
<td style="text-align: center;">8.4</td>
<td style="text-align: center;">-1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7.0</td>
<td style="text-align: center;">7.0</td>
<td style="text-align: center;">-1</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.8</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">3.0</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td style="text-align: center;">7.8</td>
<td style="text-align: center;">6.1</td>
<td style="text-align: center;">-1</td>
</tr>
</tbody>
</table>
<h2 id="single-layer-perceptron-networks-1">Single-layer perceptron networks</h2>
<ul>
<li>We can generalise the weight updating algorithm for each perceptron in the net, given a differentiable activation function, g:
<ul>
<li>Δw<sub>i,j</sub> = α . x<sub>i</sub> . ( y<sub>j</sub> – h<sub>j</sub> ) . g′( Σ<sub>k</sub>w<sub>k,j</sub>. x<sub>k</sub> )
<ul>
<li>α is the learning rate, which controls the amount of adjustment at each step</li>
<li>y<sub>i</sub> , h<sub>i</sub> are the desired and actual node outputs, respectively</li>
<li>( y<sub>j</sub> – h<sub>j</sub> ) is the error in the current node output, compared with the example</li>
<li>g′ is the derivative of the activation function; for sigmoid, g′ = g( 1 – g )</li>
<li>Σ<sub>k</sub>w<sub>k,j</sub>. x<sub>k</sub> is the value before activation at the current node ๏ ( y<sub>j</sub> – h<sub>j</sub> ) . g′(Σ<sub>k</sub>w<sub>k,j</sub>. x<sub>k</sub>) is called the Δ value (see Russell and Norvig)</li>
</ul></li>
<li>the g′ term adjusts the amount of error correction depending on the slope of the activation function</li>
</ul></li>
<li>A stopping criterion for training is based on the overall error, E
<ul>
<li>E = 0.5 . Σ<sub>i</sub> ( y<sub>j</sub> – h<sub>j</sub> )<sup>2</sup></li>
<li>This can be forced to 0, or to some allowable level of approximation</li>
</ul></li>
</ul>
<h2 id="the-bad-news-the-x-or-problem">The bad news: the X-OR problem</h2>
<ul>
<li>As we can see from the graph, the classifier is computing a straight line between two linearly separable sets of points, dividing the space in two
<ul>
<li>with more inputs, it would be a plane or hyper-plane</li>
</ul></li>
<li>If there is no straight line that partitions the set, a single perceptron cannot learn the classification
<ul>
<li>Exclusive OR is one such case</li>
</ul></li>
</ul>
<p><img src="/images/AI/1852188.png" /></p>
<h2 id="the-solution-multi-layered-nns">The solution: multi-layered NNs</h2>
<ul>
<li>The solution to this problem is to build neural networks from layers of perceptrons</li>
<li>Confusing terminology
<ul>
<li>We have so far talked about the perceptron as though it were a single thing</li>
<li>It is in fact two layers of values, one input and one output
<ul>
<li>with weighted connections connecting them</li>
</ul></li>
<li>When we talk about multiple layers, we use the number of layers of values to say how many there are</li>
</ul></li>
<li>It is mathematically proven that a network of three layers (of values) with a linear outputs layer is enough to approximate any function
<ul>
<li>there is, then, 1 hidden layer of perceptrons</li>
<li>Cybenko’s theorem, 1989, for sigmoid activation; Hornik, 1991, generalised</li>
</ul></li>
</ul>
<h2 id="a-tiny-multilayer-feed-forward-neural-network">A (tiny) multilayer feed-forward neural network</h2>
<p><img src="/images/AI/1852189.png" /></p>
<ul>
<li>Now there are two sets of weights, one for each layer
<ul>
<li>How do we train the network? The simple perceptron algorithm won’t work here</li>
</ul></li>
</ul>
<h2 id="network-training-in-general">Network training in general</h2>
<p><img src="/images/AI/1852190.png" /></p>
<ul>
<li>In general, there could be as many input units, as many hidden units and as many output units as you like
<ul>
<li>each unit is connected to every unit in the next layer, and only to the next layer</li>
<li>each connection has a weight</li>
<li>each unit in the hidden layer has an output modifier function, usually sigmoid</li>
</ul></li>
<li>Too many units leads to long training times and overfitting to data (more on that later)</li>
<li>Too few units leads to inability to learn</li>
<li>There is no known procedure to compute the required number
<ul>
<li>so skill and judgement is required!</li>
</ul></li>
</ul>
<h2 id="back-propagation-training">Back-propagation training</h2>
<ul>
<li>It turns out that we can reuse the training algorithm
<ul>
<li>apply it once per perceptron layer (so twice, in a net with 1 hidden layer)</li>
<li>start at the output layer</li>
</ul></li>
<li>Because this is working in the opposite direction from the data flow
<ul>
<li>(in a feed-forward network)</li>
<li>it is called back-propagation</li>
</ul></li>
<li>Key Idea
<ul>
<li>a hidden node j causes part of the error identified between the inputs and a given output node i, in proportion to its connection weight to i</li>
<li>so we compute the hidden layer error values by dividing the output layer error values in proportion to the connections from the hidden layer to the output layer</li>
</ul></li>
</ul>
<h2 id="back-propagation-algorithm">Back-propagation algorithm</h2>
<ul>
<li>Compute Δ values for output units, using observed error</li>
<li>Starting with output layer, and working towards input layer
<ul>
<li>propagate Δ values back from layer L to layer L – 1
<ul>
<li>for each node j in layer ( L – 1 ): Δ<sub>j</sub> = g′( Σ<sub>k</sub>w<sub>j,k</sub>. Δ k )</li>
</ul></li>
<li>update weights between layer L – 1 and layer L</li>
</ul></li>
</ul>
<p><img src="/images/AI/1852191.png" /></p>
<h2 id="testing-the-trained-network">Testing the trained network</h2>
<ul>
<li>We can train a network to model a dataset in as much detail as we like</li>
<li>However, we quite often want a network to generalise
<ul>
<li>ie, not just learn the values we told it (we know them already) but estimate the (assumed continuous) functions that gave rise to them</li>
</ul></li>
<li>If we train perfectly, we may over-fit, and miss that generality</li>
<li>To overcome this problem, divide the data into training sets and test sets, and perform cross-validation
<ul>
<li>for example, reserve 10% of the data for testing, and use 90% for training
<ul>
<li>compare the predicted 10% of values with the originals</li>
</ul></li>
<li>better, use 10-fold cross-validation:
<ul>
<li>partition the data into 10 subsets</li>
<li>cross-validation 90% vs. 10% on each combination of the 10 subsets</li>
</ul></li>
<li>can be the stopping criterion, but it is more expensive than local error</li>
</ul></li>
</ul>
<h2 id="neurally-inspired-computing">Neurally inspired computing</h2>
<ul>
<li>Much neural network research makes biologically implausible assumptions about how neurons work
<ul>
<li>backpropagation is biologically implausible</li>
<li>this is “neurally inspired computing” rather than “brain science”</li>
</ul></li>
<li>None of the neural network models distinguish humans from dogs from dolphins from flatworms
<ul>
<li>Whatever distinguishes “higher” cognitive capacities (language, reasoning) may not be apparent at this low level of analysis</li>
</ul></li>
<li>Relation between NN and “symbolic AI”?
<ul>
<li>Some claim NN models don’t have symbols and representations</li>
<li>Others think of NNs as simply being an “implementation-level” theory</li>
<li>NNs started out as a branch of statistical pattern classification</li>
<li>Other more structured statistical methods are now tending to take over, but ANNs are still popular in many applications</li>
</ul></li>
</ul>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Chaoqun Yin</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://yintelligence.tech/2021/03/07/2021-03-07-Artificial-Neural-Networks/">https://yintelligence.tech/2021/03/07/2021-03-07-Artificial-Neural-Networks/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="/about" target="_blank">Chaoqun Yin</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Techniques-of-Artificial-Intelligence/">
                                    <span class="chip bg-color">Techniques of Artificial Intelligence</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2021/03/08/2021-03-08-Inheritance/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/6.jpg" class="responsive-img" alt="Inheritance">
                        
                        <span class="card-title">Inheritance</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-03-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Discussions/" class="post-category">
                                    Discussions
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Data-Structures/">
                        <span class="chip bg-color">Data Structures</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/03/07/2021-03-07-Trees/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/5.jpg" class="responsive-img" alt="Trees">
                        
                        <span class="card-title">Trees</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-03-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Notes/" class="post-category">
                                    Notes
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Structure-and-Interpretation-of-Computer-Programs/">
                        <span class="chip bg-color">Structure and Interpretation of Computer Programs</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + 'From: Chaoqun Yin<br />'
            + 'Author: Chaoqun Yin<br />'
            + 'Link: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2021</span>
            
            <span id="year">2021</span>
            <a href="/about" target="_blank">Chaoqun Yin</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2021";
                    var startMonth = "1";
                    var startDate = "28";
                    var startHour = "2";
                    var startMinute = "1";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/yintelligence" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:Yintelligence@outlook.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
